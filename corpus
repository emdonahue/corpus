#!/bin/zsh

#TODO Make mwe match multiline expressions.
#TODO Give merge option to split lines to make large token files readable by other line-based tools. Possibly using null bytes to preserve original linebreaks.

set -o errexit
set -o pipefail
if [[ "${TRACE-0}" == "1" ]]; then set -o xtrace; fi

unset c #Reserved variable for inline comments

FS=$'\034'
US=$'\037'

CMD="$1"
[[ $# -ne 0 ]] && shift
case "$CMD" in
    --help|-h|help) #[SUBCOMMAND]; Prints help text for SUBCOMMAND. If SUBCOMMAND omitted, prints list of subcommands.
	[[ $# -eq 0 ]] && echo 'corpus - A suite of tools for cleaning textual corpora. \nUsage: corpus SUBCOMMAND [ARGUMENTS...]\n\nSubcommands:'
	sed -nE '/\s*'"$1"'\)\s#/'"${1:+,/^\s*;;\s*$/}"'{s/^[[:space:]]*([-|[:alnum:]]+)\)\s#([^;]*); (.*)/'"${${1-\t}:#$1}"'\1 \2\t\3/p; s/.*(\w+)[-+:]*=\w+ \$\{c#(.*); (.*)\}.*/\t-\1 \2\t\3/p}' "$0"
	;;
    
    charset) #[FILE...]; Prints counts of every character used in the corpus.
	awk -vOFS='\t' -vFILESEP=$FS 'substr($0,1,1)!=FILESEP {for (i=1;i<=length($0);i++) {c[substr($0,i,1)]++}} END {for (i in c) print i,c[i]}' "$@" | sort -k1,1
	;;
    
    merge) #FILE...; Merges FILES together with file separator bytes so that they can be streamed.
	awk -vFILESEP="$FS" 'BEGINFILE {print FILESEP FILENAME} {print}' "$@"
	;;
    
    mwe) #MWE...; Replace all multiword expressions MWE in the corpus on stdin with single tokens joined by a separator.
	sed -f <(printf "%s\n" "$@" | sed -E 'h;s/\s+/_/g;x;s/\s+/[[:space:]]\\+/g;G;s/\n/'$US'/;s|^|/^'$FS'/! s'$US'|;s|$|'$US'g|')
	;;
    
    split) #; Splits apart a merged file stream and writes it to separate files.
	awk -vFILESEP="$FS" 'substr($0,1,1)==FILESEP {FNAME=substr($0,2); next} {print > FNAME}'
	;;
    
    *)
	if [[ -z "$CMD" ]]; then
	    "$0" help
	else
	    "$0" help 1>&2
	    exit 1
	fi
	;;
esac
